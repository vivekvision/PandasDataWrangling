{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351d246d",
   "metadata": {},
   "source": [
    "## Handle duplicate rows in a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d032c956",
   "metadata": {},
   "source": [
    "Create a hardcoded Pandas DataFrame df with some duplicate rows. \n",
    "\n",
    "then use various methods to find and handle these duplicates.\n",
    "\n",
    "first use the duplicated() method to find duplicate rows based on all columns, as well as based on a subset of columns.\n",
    "\n",
    "then use the drop_duplicates() method to remove these duplicate rows, either based on all columns or based on a subset of columns.\n",
    "\n",
    "also use the keep parameter to keep only the first or last occurrence of each duplicate row.\n",
    "\n",
    "Finally, use the drop_duplicates() method with the keep=False parameter to keep only the rows that are not duplicates.\n",
    "\n",
    "The resulting DataFrames show the original DataFrame, the duplicate rows based on all columns and based on a subset of columns, as well as the various versions of the DataFrame with the duplicate rows handled in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475dd3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9de7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    A  B   C\n",
      "0  1  a  10\n",
      "1  2  b  20\n",
      "2  3  c  30\n",
      "3  4  d  40\n",
      "4  5  e  50\n",
      "5  2  b  20\n",
      "\n",
      "Duplicate rows:\n",
      "    A  B   C\n",
      "5  2  b  20\n",
      "\n",
      "Duplicate rows based on subset of columns:\n",
      "    A  B   C\n",
      "5  2  b  20\n",
      "\n",
      "Deduplicated DataFrame based on all columns:\n",
      "    A  B   C\n",
      "0  1  a  10\n",
      "1  2  b  20\n",
      "2  3  c  30\n",
      "3  4  d  40\n",
      "4  5  e  50\n",
      "\n",
      "Deduplicated DataFrame based on subset of columns:\n",
      "    A  B   C\n",
      "0  1  a  10\n",
      "1  2  b  20\n",
      "2  3  c  30\n",
      "3  4  d  40\n",
      "4  5  e  50\n",
      "\n",
      "DataFrame with only first occurrence of each duplicate row:\n",
      "    A  B   C\n",
      "0  1  a  10\n",
      "1  2  b  20\n",
      "2  3  c  30\n",
      "3  4  d  40\n",
      "4  5  e  50\n",
      "\n",
      "DataFrame with only last occurrence of each duplicate row:\n",
      "    A  B   C\n",
      "0  1  a  10\n",
      "2  3  c  30\n",
      "3  4  d  40\n",
      "4  5  e  50\n",
      "5  2  b  20\n",
      "\n",
      "DataFrame with no duplicate rows:\n",
      "    A  B   C\n",
      "0  1  a  10\n",
      "2  3  c  30\n",
      "3  4  d  40\n",
      "4  5  e  50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a hardcoded Pandas DataFrame with some duplicate rows\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, 5, 2],\n",
    "                   'B': ['a', 'b', 'c', 'd', 'e', 'b'],\n",
    "                   'C': [10, 20, 30, 40, 50, 20]})\n",
    "\n",
    "# find the duplicate rows based on all columns\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "# find the duplicate rows based on a subset of columns\n",
    "duplicate_rows_subset = df[df.duplicated(subset=['A', 'B'])]\n",
    "\n",
    "# drop the duplicate rows based on all columns\n",
    "df_deduped = df.drop_duplicates()\n",
    "\n",
    "# drop the duplicate rows based on a subset of columns\n",
    "df_deduped_subset = df.drop_duplicates(subset=['A', 'B'])\n",
    "\n",
    "# keep only the first occurrence of each duplicate row\n",
    "df_first_occurrence = df.drop_duplicates(keep='first')\n",
    "\n",
    "# keep only the last occurrence of each duplicate row\n",
    "df_last_occurrence = df.drop_duplicates(keep='last')\n",
    "\n",
    "# keep only the rows that are not duplicates\n",
    "df_no_duplicates = df.drop_duplicates(keep=False)\n",
    "\n",
    "# print the resulting DataFrames\n",
    "print('Original DataFrame:\\n', df)\n",
    "print('\\nDuplicate rows:\\n', duplicate_rows)\n",
    "print('\\nDuplicate rows based on subset of columns:\\n', duplicate_rows_subset)\n",
    "print('\\nDeduplicated DataFrame based on all columns:\\n', df_deduped)\n",
    "print('\\nDeduplicated DataFrame based on subset of columns:\\n', df_deduped_subset)\n",
    "print('\\nDataFrame with only first occurrence of each duplicate row:\\n', df_first_occurrence)\n",
    "print('\\nDataFrame with only last occurrence of each duplicate row:\\n', df_last_occurrence)\n",
    "print('\\nDataFrame with no duplicate rows:\\n', df_no_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fcda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
